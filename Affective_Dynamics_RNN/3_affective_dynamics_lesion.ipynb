{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Network Lesion analysis:\n",
    "\n",
    "*Yiyu Wang 2022 December*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from sklearn import svm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2022\n",
    "N_ROI = 100\n",
    "which_atlas = 'network17'\n",
    "\n",
    "# model params:\n",
    "learning_rate = 1e-3\n",
    "hidden_size = 150\n",
    "feature_dim = N_ROI\n",
    "output_size = 1\n",
    "n_layers=2\n",
    "\n",
    "# load the subjects:\n",
    "included_data = pd.read_csv('/work/abslab/AVFP/Preproc_Scripts/included_AVFP_novel_subjects.csv', header=None)\n",
    "subIDs = included_data[0].astype('str').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def GetDataName(subject, run='*'):\n",
    "#     file_name = glob.glob(f'/work/abslab/Yiyu/dnn/AVFP_parcellation/wholebrain_schaeffer_atlas-{which_atlas}_{N_ROI}/par-{subject}_run-{run}_schaefer_{N_ROI}.csv')\n",
    "#     if not file_name :\n",
    "#         raise Exception('No this parcellation csv file!')\n",
    "#     return file_name\n",
    "\n",
    "def GetDataName(subject, run='*'):\n",
    "    file_name = glob.glob(f'/work/abslab/Yiyu/dnn/AVFP_parcellation/wholebrain_schaeffer_{N_ROI}/par-{subject}_run-{run}_schaefer_{N_ROI}.csv')\n",
    "    if not file_name :\n",
    "        raise Exception('No this parcellation csv file!')\n",
    "    return file_name\n",
    "\n",
    "def CreateXY(sub_list, network = None, y_col='fear'):\n",
    "    \"\"\"\n",
    "    Run gradient descent to opimize parameters of a given network\n",
    "\n",
    "    Args:\n",
    "    sub_list: list\n",
    "        list of subject IDs to extract the data\n",
    "    network: str \n",
    "        which network to lesion, or default is no lesion \n",
    "        the network name must be in the dataframe column names\n",
    "    y_col: str\n",
    "        which column to extract the y variable\n",
    "        default = 'fear'\n",
    "\n",
    "    Returns:\n",
    "    X_tensor: Tensor\n",
    "        batch x seq x feature\n",
    "    Y_tensor: Tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    for sub in sub_list:\n",
    "        for parcellation_path in GetDataName(sub):\n",
    "            par_df =pd.read_csv(parcellation_path)\n",
    "            par_df = par_df.loc[par_df['video_name']!='0']\n",
    "            \n",
    "            if network:\n",
    "                x_cols = [col for col in par_df.columns if 'Networks' in col]\n",
    "                zero_cols = [col for col in x_cols if (network in col)]\n",
    "                par_df[zero_cols]=0\n",
    "                  \n",
    "            avg = par_df[y_col].mean()\n",
    "            std = par_df[y_col].std()\n",
    "            for vid_name, trial_df in par_df.groupby('video_name'):\n",
    "                if ~np.isnan(trial_df[y_col].unique()[0]):\n",
    "                    X.append(trial_df.iloc[:,0:N_ROI].astype(float).values)\n",
    "                    Y.append((trial_df[y_col].unique()[0]-avg)/std)\n",
    "\n",
    "    # concate the x and y\n",
    "    # x: batch x seq  x feature\n",
    "    X_tensor = torch.tensor(np.array(X))\n",
    "    # .permute(2, 1, 0)\n",
    "    Y_tensor = torch.tensor(Y)\n",
    "    return X_tensor, Y_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the RNN model:\n",
    "\n",
    "class BrainLTSM_Classifier(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size, feature_dim, n_layers):\n",
    "        super(BrainLTSM_Classifier, self).__init__()\n",
    "        \n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.feature_dim = feature_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(feature_dim, hidden_size, n_layers, batch_first=True,dropout=.2)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # batch = len(inputs) (if batch_first = True)\n",
    "        h0 = torch.randn(self.n_layers,len(inputs),self.hidden_size)\n",
    "        c0 = torch.randn(self.n_layers,len(inputs),self.hidden_size)\n",
    "        output,hidden = self.lstm(inputs,(h0, c0))\n",
    "        \n",
    "        output = self.linear(output)\n",
    "        return output, hidden\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetValLossAcc(model, loss_fn, test_dataloader,device='cpu'):\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        Y_shuffled, Y_preds = [],[]\n",
    "        for X, Y in test_dataloader:\n",
    "            X.to(device),Y.to(device)\n",
    "            preds, hidden = model(X.float())\n",
    "            test_loss = loss_fn(preds[:,-1,0], Y.float())\n",
    "\n",
    "            test_loss.append(epoch_test_loss.item())\n",
    "            Y_shuffled.append(Y)\n",
    "            Y_preds.append(preds)\n",
    "        Y_shuffled = torch.cat(Y_shuffled)\n",
    "        Y_preds = torch.cat(Y_preds)\n",
    "        test_accuracy = np.corrcoef(Y_shuffled.detach().numpy(),\n",
    "                                      Y_preds.detach().squeeze().numpy()[:,-1])[0,1]  \n",
    "\n",
    "    \n",
    "    return test_loss, test_accuracy \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "network_list = ['Vis','SomMot','DorsAttn','SalVent','Limbic','Cont','Default']\n",
    "network_score_list = []\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = SEED)\n",
    "for network in network_list:\n",
    "    fold_acc_list = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(subIDs)):\n",
    "        print(f'---------------------- fold {fold+1} ---------------------------')\n",
    "        sub_test = np.array(subIDs)[test_idx.astype(int)].tolist()\n",
    "        \n",
    "        test_X, test_Y = CreateXY(sub_test, network = network)\n",
    "        test_dataset = CustomAffVidsDynamicDataset(test_X, test_Y)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)\n",
    "    \n",
    "    \n",
    "        model_file_path = f'models/LSTM_feature-{feature_dim}_hidden-{hidden_size}_layers-{n_layers}_fold-{fold}_lr-{learning_rate}.pt'\n",
    "        print(f'loading: {model_file_path}')\n",
    "        \n",
    "        model = BrainLTSM_Classifier(output_size, hidden_size, feature_dim, n_layers)\n",
    "        model.load_state_dict(torch.load(model_file_path))\n",
    "        \n",
    "        test_acc, test_acc = GetValidationLoss(model, loss_fn, test_dataloader,device=device)\n",
    "        fold_acc_list.append(test_acc)\n",
    "    network_acc = np.mean(fold_acc_list)\n",
    "    print(f'{network}: {network_acc}')\n",
    "    network_score_list.append(network_acc)\n",
    "\n",
    "network_score = pd.DataFrame({'network': network_list, 'lesion_score': network_score_list})\n",
    "# quick visual:\n",
    "sns.barplot(data=network_score, x=\"network\", y=\"lesion_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
