{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13303e6d",
   "metadata": {},
   "source": [
    "# Fine tuning pretrained BERT models to predict reasons for Cannabis Use in Lupus Patients EHR\n",
    "\n",
    "based on Nathan Le's code, extending to different fine-tuning strategies\n",
    "\n",
    "*yiyu wang 2025/02*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ce3a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb56bd3-f20e-4431-9a1e-c4cabb40d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/yiyuwang/Projects/CannabisUse/'  \n",
    "\n",
    "df_train = pd.DataFrame(columns=['sentiment', 'Snippets'])\n",
    "\n",
    "# Add new data (first batch)\n",
    "df_new = pd.read_csv(path + 'use_case_active_learning_1.csv')\n",
    "\n",
    "df_new['sentiment'] = df_new['Sentiment'].astype(int)\n",
    "df_new = df_new.rename(columns={'text': 'Snippets'})  \n",
    "\n",
    "df_train = pd.concat([df_train, df_new[['sentiment', 'Snippets']]], ignore_index=True)\n",
    "\n",
    "# Add new data (second batch)\n",
    "\n",
    "df_new = pd.read_csv(path + 'use_case_active_learning_2.csv')\n",
    "\n",
    "df_new['sentiment'] = df_new['Sentiment'].astype(int)\n",
    "df_new = df_new.rename(columns={'text': 'Snippets'})  \n",
    "\n",
    "df_train = pd.concat([df_train, df_new[['sentiment', 'Snippets']]], ignore_index=True)\n",
    "\n",
    "# Add new data (third batch)\n",
    "\n",
    "df_new = pd.read_csv(path + 'use_case_active_learning_3.csv')\n",
    "\n",
    "df_new['sentiment'] = df_new['Sentiment'].astype(int)\n",
    "df_new = df_new.rename(columns={'text': 'Snippets'})  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_train = pd.concat([df_train, df_new[['sentiment', 'Snippets']]], ignore_index=True)\n",
    "\n",
    "df_train, df_test = train_test_split(df_train, test_size=0.2, random_state=50)\n",
    "\n",
    "# convert sentiment from 1- 7 to 0 - 6\n",
    "df_train['sentiment'] = df_train['sentiment'] - 1\n",
    "df_test['sentiment'] = df_test['sentiment'] - 1\n",
    "\n",
    "\n",
    "best_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8878fd-b214-4b42-8b7a-205b46c5de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e112642-f60b-440e-94e4-3037920a57f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3739cd5-9e7b-40b3-8096-4c8b36013221",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info(),df_test.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4fca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of the seven class in sentiment\n",
    "class_label_names = ['pain', 'nausea', 'sleep', 'anxiety/stress/relexation', 'unknown', 'not use','appetite']\n",
    "sns.barplot(x=df_train.sentiment.value_counts().index, y=df_train.sentiment.value_counts())\n",
    "plt.xticks(ticks=range(7), labels=class_label_names, rotation=45)\n",
    "plt.xlabel('sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c547c1ab-0166-4ef1-b15d-fbbbe6fa86de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape,df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeebf1b-baa0-4b5e-acb7-4034e142d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "# PRE_TRAINED_MODEL_NAME=\"roberta-large-mnli\"\n",
    "PRE_TRAINED_MODEL_NAME=\"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f4640-0c48-4941-b128-0c7f5e6b6fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.sep_token, tokenizer.sep_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed777e68-b233-4cc3-b115-ae25ca85b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.cls_token, tokenizer.cls_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91422c0b-d092-4e63-95bb-4fd13a1259fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token, tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb7fba1-1b0e-427c-b880-c4d4f5834660",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.unk_token, tokenizer.unk_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9919441-dcd4-4709-a1f6-f038a18fa366",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lens=[]\n",
    "for txt in df_train.Snippets:\n",
    "  tokens=tokenizer.encode(txt,max_length=512)\n",
    "  token_lens.append(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d00e4c-579b-4001-b82c-d745aa1e96e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(token_lens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a3038d-a421-4e74-a9b2-4272a5c6bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CannabisClassData(Dataset):\n",
    "  def __init__(self, text, label, tokenizer, max_len):\n",
    "    self.text=text\n",
    "    self.label=label\n",
    "    self.tokenizer=tokenizer\n",
    "    self.max_len=max_len\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.text)\n",
    "  \n",
    "  def __getitem__(self,item):\n",
    "    text= str(self.text[item])\n",
    "    label=self.label[item]\n",
    "    encoding=self.tokenizer.encode_plus(\n",
    "    text,\n",
    "    max_length=self.max_len,\n",
    "    add_special_tokens=True,\n",
    "    pad_to_max_length=True,\n",
    "    truncation =True,\n",
    "    return_attention_mask=True,\n",
    "    return_token_type_ids=False,\n",
    "    return_tensors='pt'\n",
    "    )\n",
    "    return{\n",
    "        'text':text,\n",
    "        'input_ids': encoding['input_ids'].flatten(),\n",
    "        'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        'label':torch.tensor(label,dtype=torch.long)\n",
    "    }\n",
    "\n",
    "class MLMDataset(Dataset):\n",
    "    def __init__(self, texts, label, tokenizer, max_len):\n",
    "        self.label=label\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_len)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label=self.label[idx]\n",
    "        encoding = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        return{\n",
    "        'input_ids': encoding['input_ids'].flatten(),\n",
    "        'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        'labels':torch.tensor(label,dtype=torch.long)\n",
    "    }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb3b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size, collate_fn=None):\n",
    "  ds = CannabisClassData(\n",
    "    text=df.Snippets.to_numpy(),\n",
    "    label=df.sentiment.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    "  )\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635711c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CannabisClassifier(nn.Module):\n",
    "  def __init__(self,n_classes):\n",
    "    super(CannabisClassifier,self).__init__()\n",
    "    self.bert=AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "    self.drop=nn.Dropout(p=0.3)\n",
    "    self.out=nn.Linear(self.bert.config.hidden_size,n_classes)\n",
    "    self.softmax=nn.Softmax(dim=1)\n",
    "  def forward(self,input_ids,attention_mask):\n",
    "    _,pooled_output=self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      return_dict=False\n",
    "    )\n",
    "    output=self.drop(pooled_output)\n",
    "    output=self.out(output)\n",
    "    #return self.softmax(output)\n",
    "    return nn.LogSoftmax(dim=1)(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b849d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CannabisClassifierFrozenBackbone(nn.Module):\n",
    "    def __init__(self, PRE_TRAINED_MODEL_NAME, n_classes):\n",
    "        super(CannabisClassifierFrozenBackbone, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "        self.drop=nn.Dropout(p=0.1)\n",
    "        self.out = nn.Linear(hidden_size, n_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=False\n",
    "        )\n",
    "        output=self.drop(pooled_output)\n",
    "        output=self.out(output)\n",
    "        #return self.softmax(output)\n",
    "        return nn.LogSoftmax(dim=1)(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71a9148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model,\n",
    "    data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    n_examples\n",
    "):\n",
    "    model=model.train()\n",
    "\n",
    "    losses=[]\n",
    "    correct_predictions=0\n",
    "\n",
    "    for d in data_loader:\n",
    "      input_ids=d['input_ids'].to(device)\n",
    "      attention_mask=d['attention_mask'].to(device)\n",
    "      label=d['label'].to(device)\n",
    "\n",
    "\n",
    "      outputs=model(\n",
    "          input_ids=input_ids,\n",
    "          attention_mask=attention_mask\n",
    "      )\n",
    "\n",
    "      preds=torch.max(outputs,dim=1)\n",
    "      loss=loss_fn(outputs,label)\n",
    "\n",
    "      #correct_predictions += torch.sum(torch.eq(preds, label))\n",
    "      correct_predictions +=torch.sum(torch.eq(torch.argmax(outputs,dim=1).cpu(), label.cpu()))\n",
    "      losses.append(loss.item())\n",
    "\n",
    "      loss.backward()\n",
    "      nn.utils.clip_grad_norm_(model.parameters(),max_norm=1.0)\n",
    "      optimizer.step()\n",
    "      scheduler.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d515671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      label = d[\"label\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      loss = loss_fn(outputs, label)\n",
    "\n",
    "      #correct_predictions += torch.sum(torch.eq(preds, label))\n",
    "      correct_predictions +=torch.sum(torch.eq(torch.argmax(outputs,dim=1).cpu(), label.cpu()))\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f560da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "  model = model.eval()\n",
    "  \n",
    "  texts = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  real_values = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "\n",
    "      text = d[\"text\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      label = d[\"label\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "      text.extend(text)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(probs)\n",
    "      real_values.extend(label)\n",
    "\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "  return text, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0d6ee-779f-485f-9207-e3df87f3d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS=10\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca1a9ca-42fd-4c4b-b344-33bdac4eab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape,  df_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa10f12-c338-4276-8489-1c0f330ecf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869ed67-8e50-4a3c-8c78-57b1c5b57600",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=next(iter(train_data_loader))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6f35ce-a828-425c-840c-4041471e52b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['input_ids'].shape)\n",
    "print(data['attention_mask'].shape)\n",
    "print(data['label'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8212b45",
   "metadata": {},
   "source": [
    "# 1. Regular Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e94ba-ff31-4f26-b86a-1d596339c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ClinicalBertmodel = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e784607-b6d3-4b7e-86d7-fe3257ccc47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CannabisClassifier(len(np.unique(df_train.sentiment)))\n",
    "model=model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9848c0b-c817-4bf6-a2de-cb3cb8853e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_ids=data['input_ids'].to(device)\n",
    "attention_mask=data['attention_mask'].to(device)\n",
    "print(input_ids.shape)\n",
    "print(attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e1aea-29b4-421a-8a7c-33e0fee1548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(input_ids,attention_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=AdamW(model.parameters(),lr=2e-5,correct_bias=False)\n",
    "total_steps=len(train_data_loader)*EPOCHS\n",
    "scheduler=get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d8a32c-7829-4b0c-ad3c-788435b0344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_WT=True\n",
    "if LOSS_WT: \n",
    "    weights = torch.tensor([1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0]).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=weights).to(device)\n",
    "else:\n",
    "    loss_fn=nn.CrossEntropyLoss().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be614613-8c88-4dc9-8f60-1ab6f477e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,    \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device, \n",
    "    scheduler, \n",
    "    len(df_train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc75d36-a8ab-44a9-95fc-7a81a8ccde32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  model,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "\n",
    "best_acc.append(test_acc.item())\n",
    "\n",
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e8fe2e-e165-4149-b617-7d2c730b9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  model,\n",
    "  test_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a64365-8845-4b08-8a33-cc94fea82411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['sentiment'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98279a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7913531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9581eb23-484a-46c1-8aec-725587da4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['0', '1','2','3','4','5', '6']\n",
    "class_label_names = ['pain', 'nausea', 'sleep', 'anxiety/stress/relexation', 'unknown', 'not use', 'appetite']\n",
    "print(classification_report(y_test, y_pred,target_names=class_label_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99726e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), path + 'CannabisClassifier_model-ClinicalBERT_dropout-3_batch-32.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34366af3",
   "metadata": {},
   "source": [
    "# 2. adapt using MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c03c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec3f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "# PRE_TRAINED_MODEL_NAME = 'RoBERTa-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d893a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_adapt_mlm(model, tokenizer, data_collator, df_train, max_len=MAX_LEN, batch_size=BATCH_SIZE):\n",
    "    # Fine-tune the base model with MLM\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer=AdamW(model.parameters(),lr=2e-5, correct_bias=False)\n",
    "    ds =MLMDataset(texts=df_train.Snippets.to_list(),\n",
    "        label=df_train.sentiment.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len)\n",
    "\n",
    "    train_data_loader = DataLoader(ds, batch_size=batch_size, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch in tqdm(train_data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            outputs = model(**inputs, labels=inputs['input_ids'])\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf73380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "mlm_model = AutoModelForMaskedLM.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n",
    "\n",
    "mlm_model = domain_adapt_mlm(mlm_model, tokenizer, data_collator, df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fab489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a classification model with MLP\n",
    "class CannabisUseMLPClassifier(nn.Module):\n",
    "    def __init__(self, base_model, num_classes):\n",
    "        super().__init__()\n",
    "        self.roberta = base_model\n",
    "        hidden_size = base_model.config.hidden_size\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        return self.classifier(pooled_output)\n",
    "\n",
    "# Initialize the classification model\n",
    "base_model = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "base_model_dict = base_model.state_dict()\n",
    "pretrained_dict = mlm_model.bert.state_dict()\n",
    "base_model_dict.update({k: v for k, v in pretrained_dict.items() if k in base_model_dict})\n",
    "base_model.load_state_dict(base_model_dict)\n",
    "classification_model = CannabisUseMLPClassifier(base_model, num_classes=7)\n",
    "classification_model.to(device)\n",
    "\n",
    "optimizer=AdamW(classification_model.parameters(),lr=2e-5, correct_bias=False)\n",
    "\n",
    "total_steps=len(train_data_loader)*EPOCHS\n",
    "scheduler=get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "# Train the classification model\n",
    "\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "\n",
    "weight_loss=True\n",
    "if weight_loss:\n",
    "    weights = torch.tensor([1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0]).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=weights).to(device)\n",
    "else:\n",
    "    loss_fn=nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    classification_model,\n",
    "    train_data_loader,    \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device, \n",
    "    scheduler, \n",
    "    len(df_train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5ec0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011fc640",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  classification_model,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "best_acc.append(test_acc.item())\n",
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a040627",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  classification_model,\n",
    "  test_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a87813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['0', '1','2','3','4','5', '6']\n",
    "class_label_names = ['pain', 'nausea', 'sleep', 'anxiety/stress/relexation', 'unknown', 'not use', 'appetite']\n",
    "print(classification_report(y_test, y_pred,target_names=class_label_names))\n",
    "\n",
    "# save model\n",
    "torch.save(classification_model.state_dict(), path + 'CannabisClassifier_model-ClinicalBERT_MLM_dropout-3_batch-32.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5de709",
   "metadata": {},
   "source": [
    "# 3. only fine tuning last linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=CannabisClassifierFrozenBackbone(PRE_TRAINED_MODEL_NAME, len(np.unique(df_train.sentiment)))\n",
    "model3=model3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940acbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model3,\n",
    "    train_data_loader,    \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device, \n",
    "    scheduler, \n",
    "    len(df_train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0f914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  model3,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "best_acc.append(test_acc.item())\n",
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74413eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  model3,\n",
    "  test_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa35cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['0', '1','2','3','4','5','6']\n",
    "print(classification_report(y_test, y_pred, target_names=['pain', 'nausea', 'sleep', 'anxiety', 'unknown', 'not current use', 'appetite']))\n",
    "\n",
    "# save\n",
    "torch.save(model3.state_dict(), f'{path}/CannabisClassifier_model-ClinicalBERT_FrozenBackbone_dropout-3_batch-32.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79765b3",
   "metadata": {},
   "source": [
    "# 4. fine tune using ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b64152",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensemble Model\n",
    "class CannabisUseEnsembleModel(nn.Module):\n",
    "    def __init__(self, models, num_classes, hidden_size=768):\n",
    "        super().__init__()\n",
    "        self.models = nn.ModuleList(models)\n",
    "        \n",
    "        # Number of models in the ensemble\n",
    "        self.num_models = len(models)\n",
    "        \n",
    "        # Classifier layer\n",
    "        self.classifier = nn.Linear(hidden_size * self.num_models, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get outputs from all models\n",
    "        model_outputs = [model(input_ids, attention_mask).last_hidden_state[:, 0, :] for model in self.models]\n",
    "        \n",
    "        # Concatenate the outputs\n",
    "        concatenated_outputs = torch.cat(model_outputs, dim=1)\n",
    "        \n",
    "        # Pass through the classifier\n",
    "        logits = self.classifier(concatenated_outputs)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "    def get_logits(self, input_ids, attention_mask):\n",
    "        # This method returns individual model logits and ensemble logits\n",
    "        individual_logits = [model(input_ids, attention_mask).logits for model in self.models]\n",
    "        ensemble_logits = self.forward(input_ids, attention_mask)\n",
    "        return individual_logits, ensemble_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec8a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10\n",
    "BATCH_SIZE = 32\n",
    "MAX_LEN=128\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f16bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "PRE_TRAINED_MODEL_NAME = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "num_classes = 7\n",
    "# Assume you have 3 pre-trained models\n",
    "model1 = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model2 = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model3 = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "# Create the ensemble\n",
    "ensemble = CannabisUseEnsembleModel([model1, model2, model3], num_classes=num_classes)\n",
    "\n",
    "# fine tune the ensemble model\n",
    "ensemble.to(device)\n",
    "\n",
    "optimizer=AdamW(ensemble.parameters(),lr=2e-5, correct_bias=False)\n",
    "\n",
    "weight_loss=True\n",
    "if weight_loss:\n",
    "    weights = torch.tensor([1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0]).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=weights).to(device)\n",
    "else:\n",
    "    loss_fn=nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "for epoch in range(EPOCHS):\n",
    "    ensemble.train()\n",
    "    for batch in tqdm(train_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'label' and k != 'text'}\n",
    "        outputs = ensemble(**inputs)\n",
    "        preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, batch['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62119081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n",
    "\n",
    "test_acc, _ = eval_model(\n",
    "  ensemble,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "\n",
    "best_acc.append(test_acc.item())\n",
    "print(test_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a76afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  ensemble,\n",
    "  test_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7ea2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['0', '1','2','3','4','5','6']\n",
    "print(classification_report(y_test, y_pred, target_names=['pain', 'nausea', 'sleep', 'anxiety', 'unknown', 'not current use', 'appetite']))\n",
    "\n",
    "# save model\n",
    "torch.save(ensemble.state_dict(), path + f'CannabisClassifier_model-ensemble_batch-{BATCH_SIZE}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c01b32a",
   "metadata": {},
   "source": [
    "# 5. MLM + ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d4120",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n",
    "\n",
    "# Models to use in ensemble\n",
    "model_names = [\"emilyalsentzer/Bio_ClinicalBERT\", \"roberta-base\", \"distilbert-base-uncased\"]\n",
    "\n",
    "# Perform domain adaptation on each model\n",
    "adapted_models = []\n",
    "for name in model_names:\n",
    "    model = AutoModelForMaskedLM.from_pretrained(name)\n",
    "    adapted_model = domain_adapt_mlm(model, tokenizer, data_collator, df_train)\n",
    "    adapted_models.append(adapted_model)\n",
    "\n",
    "\n",
    "# Create ensemble of domain-adapted models\n",
    "num_classes = 7 \n",
    "ensemblemlm = CannabisUseEnsembleModel([AutoModel.from_pretrained(name) for name in model_names], num_classes)\n",
    "\n",
    "# update the ensemble with the weights from the adapted models\n",
    "for i, model_name in enumerate(model_names):\n",
    "    adapted_model = adapted_models[i]\n",
    "    base_model_dict = ensemblemlm.models[i].state_dict()\n",
    "    pretrained_dict = adapted_model.state_dict()\n",
    "    base_model_dict.update({k: v for k, v in pretrained_dict.items() if k in base_model_dict})\n",
    "    ensemblemlm.models[i].load_state_dict(base_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea6012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the ensemble with the weights from the adapted models\n",
    "for i, model_name in enumerate(model_names):\n",
    "    adapted_model = adapted_models[i]\n",
    "    base_model_dict = ensemblemlm.models[i].state_dict()\n",
    "    pretrained_dict = adapted_model.state_dict()\n",
    "    base_model_dict.update({k: v for k, v in pretrained_dict.items() if k in base_model_dict})\n",
    "    ensemblemlm.models[i].load_state_dict(base_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec18159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the ensemble model for the classification task\n",
    "\n",
    "ensemblemlm.to(device)\n",
    "\n",
    "optimizer=AdamW(ensemblemlm.parameters(),lr=2e-5, correct_bias=False)\n",
    "\n",
    "weight_loss=True\n",
    "if weight_loss:\n",
    "    weights = torch.tensor([1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0]).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=weights).to(device)\n",
    "else:\n",
    "    loss_fn=nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "for epoch in range(EPOCHS):\n",
    "    ensemblemlm.train()\n",
    "    for batch in tqdm(train_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'label' and k != 'text'}\n",
    "        outputs = ensemblemlm(**inputs)\n",
    "        preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, batch['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb91970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  ensemble,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "best_acc.append(test_acc.item())\n",
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd8fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  ensemblemlm,\n",
    "  test_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939d9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['0', '1','2','3','4','5','6']\n",
    "print(classification_report(y_test, y_pred, target_names=['pain', 'nausea', 'sleep', 'anxiety', 'unknown', 'not current use', 'appetite']))\n",
    "\n",
    "# save model\n",
    "torch.save(ensemblemlm.state_dict(), path + 'CannabisClassifier_model-ensembleMLM_batch-{BATCH_SIZE}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b6bdd7",
   "metadata": {},
   "source": [
    "# 6. fine tune attention layers + classification layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c6666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CannabisUsePurposeAttentionClassifier(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_labels):\n",
    "        super().__init__()\n",
    "        self.bert = pretrained_model\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        \n",
    "        # Freeze all parameters except attention\n",
    "        for name, param in self.bert.named_parameters():\n",
    "            if 'attention' not in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]\n",
    "        return self.classifier(pooled_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1585c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10\n",
    "BATCH_SIZE = 32\n",
    "MAX_LEN=128\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PRE_TRAINED_MODEL_NAME = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "base_model = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "modelatt=CannabisUsePurposeAttentionClassifier(base_model, len(np.unique(df_train.sentiment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=AdamW(modelatt.parameters(),lr=2e-5, correct_bias=False)\n",
    "\n",
    "total_steps=len(train_data_loader)*EPOCHS\n",
    "scheduler=get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921ef1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_loss=True\n",
    "if weight_loss:\n",
    "    weights = torch.tensor([1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0]).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=weights).to(device)\n",
    "else:\n",
    "    loss_fn=nn.CrossEntropyLoss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba4749",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    modelatt,\n",
    "    train_data_loader,    \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device, \n",
    "    scheduler, \n",
    "    len(df_train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d479173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  modelatt,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "best_acc.append(test_acc.item())\n",
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f46da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  modelatt,\n",
    "  test_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb6eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['0', '1','2','3','4','5','6']\n",
    "print(classification_report(y_test, y_pred, target_names=['pain', 'nausea', 'sleep', 'anxiety', 'unknown', 'not current use', 'appetite']))\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), path + f'/CannabisClassifier_model-ClinicalBERT_finetune-attention_batch-{BATCH_SIZE}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20707fd0",
   "metadata": {},
   "source": [
    "# FINAL STEP: classify the rest of the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a2b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best accuracy = \", np.max(best_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9896ef03-9311-4a0b-b16e-41f6cd3d4a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to use the model to classify all of the notes\n",
    "# load model from saved state_dict\n",
    "num_classes = 7\n",
    "model=CannabisClassifier(len(np.unique(df_train.sentiment)))\n",
    "model.load_state_dict(torch.load(path + 'CannabisClassifier_model-ClinicalBERT_dropout-3_batch-32.pth'))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "unlabeled_notes_path = path + \"full_list_of_5.csv\" \n",
    "output_predictions_path = path + \"fully_labeled_notes.csv\"  \n",
    "\n",
    "unlabeled_df = pd.read_csv(unlabeled_notes_path)\n",
    "unlabeled_texts = unlabeled_df['Relevant Snippets'].tolist()  \n",
    "patient_ids = unlabeled_df['Patient Id'].tolist()  \n",
    "dates = unlabeled_df['Date'].tolist()  \n",
    "\n",
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=128,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',  \n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten()\n",
    "        }\n",
    "\n",
    "unlabeled_dataset = UnlabeledDataset(unlabeled_texts, tokenizer, max_len=128)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(tqdm(unlabeled_loader, desc=\"Classifying Notes\")):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        texts = batch['text']\n",
    "\n",
    "        # Get model outputs\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        predicted_labels = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "        for i in range(len(texts)):\n",
    "            global_index = batch_idx * 32 + i  \n",
    "            predictions.append({\n",
    "                'Patient Id': patient_ids[global_index],\n",
    "                'Date': dates[global_index],\n",
    "                'Relevant Snippets': texts[i],\n",
    "                'Predicted Label': predicted_labels[i].item(),\n",
    "                'Confidence': probabilities[i].max().item()\n",
    "            })\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "# shift the label to 1-7\n",
    "predictions_df['Predicted Label'] = predictions_df['Predicted Label'] + 1\n",
    "predictions_df.to_csv(output_predictions_path, index=False)\n",
    "print(f\"Predictions saved to {output_predictions_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee33bc1-230c-4037-a5d4-580f7d1ac1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e1bdf-4240-4a2c-82a5-71cff727d7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
